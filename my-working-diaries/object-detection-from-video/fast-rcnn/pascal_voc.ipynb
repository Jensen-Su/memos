{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# **How PASCAL VOC2007 dataset comes into data input blobs to network in Fast R-CNN**\n",
    "\n",
    "    By Jincheng Su@HikVision, Shanghai, 2017/07/12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preparing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "1. Download the training, validation, test data and VOCdevkit\n",
    "```shell\n",
    "    wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
    "    wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n",
    "    wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCdevkit_08-Jun-2007.tar (jcsu: seems to be optional)\n",
    "```    \n",
    "    But these links are invalid inside the WALL. -_-\n",
    "\n",
    "2. Extract all of these tars into one directory named VOCdevkit\n",
    "```shell\n",
    "    tar xvf VOCtrainval_06-Nov-2007.tar\n",
    "    tar xvf VOCtest_06-Nov-2007.tar\n",
    "    tar xvf VOCdevkit_08-Jun-2007.tar\n",
    "```    \n",
    "3. It should have this basic structure (jcsu: The VOCcode seems to be optional)\n",
    "```shell\n",
    "    $ VOCdevkit/                           # development kit\n",
    "    $ VOCdevkit/VOCcode/                   # VOC utility code\n",
    "    $ VOCdevkit/VOC2007                    # image sets, annotations, etc.\n",
    "    $ ls VOC2007\n",
    "      Annotations  ImageSets  JPEGImages  SegmentationClass  SegmentationObject\n",
    "    # ... and several other directories ...\n",
    "```\n",
    "4. Create symlinks for the PASCAL VOC dataset\n",
    "```shell\n",
    "    cd $FRCN_ROOT/data\n",
    "    ln -s $VOCdevkit VOCdevkit2007\n",
    "```    \n",
    "    Using symlinks is a good idea because you will likely want to share the same PASCAL dataset installation between multiple projects.\n",
    "\n",
    "5. [Optional] follow similar steps to get PASCAL VOC 2010 and 2012\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## What is in the PASCAL VOC 2007 dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Directory `SegmentationClass` seems to be unrelated to Fast R-CNN.\n",
    "\n",
    "### The `JPEGImages` directory\n",
    "```shell\n",
    "    $ cd VOCdevkit/VOC2007\n",
    "    $ ls\n",
    "    Annotations  ImageSets  JPEGImages  SegmentationClass\n",
    "    $ ls JPEGImages\n",
    "    000001.jpg  001642.jpg  003283.jpg  004924.jpg  006565.jpg\n",
    "    000002.jpg  001643.jpg  003284.jpg  004925.jpg  006566.jpg\n",
    "    000003.jpg  001644.jpg  003285.jpg  004926.jpg  006567.jpg\n",
    "    ...\n",
    "```\n",
    "### The `ImageSets` directory\n",
    "```shell\n",
    "    $ ls ImageSets\n",
    "    Layout  Main  Segmentation\n",
    "    $ ls ImageSets/Main\n",
    "    aeroplane_test.txt cat_test.txt person_test.txt\n",
    "    aeroplane_train.txt cat_train.txt person_train.txt\n",
    "    aeroplane_trainval.txt cat_trainval.txt person_trainval.txt\n",
    "    ...\n",
    "    $ vim ImageSets/Main/trainval.txt\n",
    "    000005\n",
    "    000007\n",
    "    000009\n",
    "    000012\n",
    "    000016\n",
    "    ...\n",
    "```\n",
    "### The `Annotation` directory\n",
    "```shell\n",
    "    $ ls Annotations\n",
    "    000001.xml  001662.xml  003323.xml  004984.xml  006645.xml \n",
    "    000002.xml  001663.xml  003324.xml  004985.xml  006646.xml\n",
    "    000003.xml  001664.xml  003325.xml  004986.xml  006647.xml\n",
    "    ...\n",
    "    $ vim Annotations/000001.xml\n",
    "```\n",
    "```xml\n",
    "    <annotation>\n",
    "        <folder>VOC2007</folder>\n",
    "        <filename>000001.jpg</filename>\n",
    "        <source>\n",
    "            <database>The VOC2007 Database</database>\n",
    "            <annotation>PASCAL VOC2007</annotation>\n",
    "            <image>flickr</image>\n",
    "            <flickrid>341012865</flickrid>\n",
    "        </source>\n",
    "        <owner>\n",
    "            <flickrid>Fried Camels</flickrid>\n",
    "            <name>Jinky the Fruit Bat</name>\n",
    "        </owner>\n",
    "        <size>\n",
    "            <width>353</width>\n",
    "            <height>500</height>\n",
    "            <depth>3</depth>\n",
    "        </size>\n",
    "        <segmented>0</segmented>\n",
    "        <object>\n",
    "            <name>dog</name>\n",
    "            <pose>Left</pose>\n",
    "            <truncated>1</truncated>\n",
    "            <difficult>0</difficult>\n",
    "            <bndbox>\n",
    "                <xmin>48</xmin>\n",
    "                <ymin>240</ymin>\n",
    "                <xmax>195</xmax>\n",
    "                <ymax>371</ymax>\n",
    "            </bndbox>\n",
    "        </object>\n",
    "        <object>\n",
    "            <name>person</name>\n",
    "            <pose>Left</pose>\n",
    "            <truncated>1</truncated>\n",
    "            <difficult>0</difficult>\n",
    "            <bndbox>\n",
    "                <xmin>8</xmin>\n",
    "                <ymin>12</ymin>\n",
    "                <xmax>352</xmax>\n",
    "                <ymax>498</ymax>\n",
    "            </bndbox>\n",
    "        </object>\n",
    "    </annotation>\n",
    "```\n",
    "\n",
    "Directory `Annotation` contains many `.xml` files, one for each image, which contain ground-truth bounding box annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## [to do] Using selective search method to extract bounding boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "   ## Creating `imdb` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<font color=red>**NOTE: To follow the code below, please switch to directory `FRCN_ROOT/lib/datasets`.**</font>\n",
    "\n",
    "The basic `imdb` database structure is defined under `FRCN_ROOT/lib/datasets`, mainly in module `pascal_voc.py`. \n",
    "\n",
    "Let's begin from it!\n",
    "\n",
    "```shell\n",
    "    $ vim pascal_voc.py\n",
    "```\n",
    "```python\n",
    "    import datasets\n",
    "    import datasets.pascal_voc\n",
    "    import os\n",
    "    #...\n",
    "    import subprocess\n",
    "    \n",
    "    class pascal_voc(datasets.imdb):\n",
    "        def __init__(self, image_set, year, devkit_path=None):\n",
    "            datasets.imdb.__init__(self, 'voc_' + year + '_' + image_set)\n",
    "            self._year = year\n",
    "            self._image_set = image_set\n",
    "            self._devkit_path = self._get_default_path() if devkit_path is None \\\n",
    "                                else devkit_path\n",
    "            self._data_path = os.path.join(self._devkit_path, 'VOC' + self._year)\n",
    "            self._classes = ('__background__', # always index 0\n",
    "                             'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "                             'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "                             'cow', 'diningtable', 'dog', 'horse',\n",
    "                             'motorbike', 'person', 'pottedplant',\n",
    "                             'sheep', 'sofa', 'train', 'tvmonitor')\n",
    "            self._class_to_ind = dict(zip(self.classes, xrange(self.num_classes)))\n",
    "            self._image_ext = '.jpg'\n",
    "            self._image_index = self._load_image_set_index()\n",
    "            # Default to roidb handler\n",
    "            self._roidb_handler = self.selective_search_roidb\n",
    "\n",
    "            # PASCAL specific config options\n",
    "            self.config = {'cleanup'  : True,\n",
    "                           'use_salt' : True,\n",
    "                           'top_k'    : 2000}\n",
    "\n",
    "            assert os.path.exists(self._devkit_path), \\\n",
    "                    'VOCdevkit path does not exist: {}'.format(self._devkit_path)\n",
    "            assert os.path.exists(self._data_path), \\\n",
    "                    'Path does not exist: {}'.format(self._data_path)\n",
    "    # ...\n",
    "```\n",
    "\n",
    "The `imdb` structure of PASCAL VOC 2007 dataset is mainly defined by this class `pascal_voc`. We can see that there are 21 classes including `background`.\n",
    "\n",
    "To understand how it construct the `imdb` database, let's dive into the code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1. def selective_search_roidb(self)\n",
    "```python\n",
    "\"\"\"\n",
    "Return the database of selective search regions of interest.\n",
    "Ground-truth ROIs are also included.\n",
    "\n",
    "This function loads/saves from/to a cache file to speed up future calls.\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io as sio\n",
    "\n",
    "## Loading `gt_roidb` => `self.gt_roidb()`\n",
    "## If we are running this function for the first time:\n",
    "## In `self.gt_roidb()` => `self._load_pascal_annotation(image_index)`\n",
    "## Returned a dict:\n",
    "##     {'boxes' : boxes,\n",
    "##      'gt_classes': gt_classes,\n",
    "##      'gt_overlaps' : overlaps,\n",
    "##      'flipped' : False}\n",
    "\n",
    "## But here we assume that the `gt_roidb` has been saved in a `.pkl` file,\n",
    "## and we are loading the `gt_roidb` from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. def gt_roidb(self)\n",
    "```python\n",
    "\"\"\"\n",
    "Return the database of ground-truth regions of interest.\n",
    "\n",
    "This function loads/saves from/to a cache file to speed up future calls.\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gt_roidb_filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-924c521619f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mgt_roidb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcpk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"voc_2007_trainval gt roidb loaded from file:\\n'{}'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_roidb_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gt_roidb_filename' is not defined"
     ]
    }
   ],
   "source": [
    "import cPickle as cpk\n",
    "data_root = '../../data/'\n",
    "gt_file = os.path.join(data_root, 'cache/voc_2007_trainval_gt_roidb.pkl')\n",
    "if os.path.exists(gt_file):\n",
    "    with open(gt_file, 'rb') as fid:\n",
    "        gt_roidb = cpk.load(fid)\n",
    "print \"voc_2007_trainval gt roidb loaded from file:\\n'{}'\".format(gt_roidb_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Let's digress for a while to have a look at how the `gt_roidb` looks like\n",
    "print \"type(gt_roidb) = \", type(gt_roidb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print \"len(gt_roidb) = \", len(gt_roidb)\n",
    "print \"gt_roidb[0] = \\n\", gt_roidb[0]\n",
    "print \"\\ngt_roidb[1] = \\n\", gt_roidb[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"gt_roidb[0]['gt_overlaps']:\\n\", gt_roidb[0]['gt_overlaps']\n",
    "print \"\\ngt_roidb[1]['gt_overlaps']:\\n\", gt_roidb[1]['gt_overlaps']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now that we have loaded the ground-truth annotation, next step is to load the bounding boxes proposal extracted by selective search. Let's go to this line:            \n",
    "\n",
    "`ss_roidb = self._load_selective_search_roidb(gt_roidb)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3. `def _load_selective_search_roidb(self, gt_roidb):`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io as sio\n",
    "\n",
    "## load selective search data\n",
    "ss_file = os.path.join(data_root, 'selective_search_data/voc_2007_trainval.mat')\n",
    "\n",
    "assert os.path.exists(ss_file), 'Selective search data not found at: {}'.format(filename)\n",
    "\n",
    "raw_data = sio.loadmat(ss_file)['boxes'].ravel()\n",
    "\n",
    "## raw_data.shape = (5011,), raw_data[0].shape = (2443, 4)\n",
    "\n",
    "box_list = []\n",
    "\n",
    "for i in xrange(raw_data.shape[0]):\n",
    "    box_list.append(raw_data[i][:, (1, 0, 3, 2)] - 1)\n",
    "\n",
    "## load gt_roidb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Now that we have both `box_list` and `gt_roidb`, we are ready to diving into function `create_roidb_from_box_list(box_list, gt_roidb)`**\n",
    "\n",
    "### 4. def create_roidb_from_box_list(self, box_list, gt_roidb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxes.shape =  (2443, 4)\n",
      "numb_boxes =  2443\n",
      "overlaps.shape =  (2443, 21)\n"
     ]
    }
   ],
   "source": [
    "## `num_images` of trainval set is 5011, \n",
    "## see 'VOC2007/ImageSets/Main.trainval.txt'\n",
    "import numpy as np\n",
    "num_images = 5011\n",
    "num_classes = 21\n",
    "assert len(box_list) == num_images, \"Number of boxes must match number of ground-truth images\"\n",
    "\n",
    "## The original code is in a for-loop,\n",
    "## but we only focus on one iteration of the loop.\n",
    "boxes = box_list[0]\n",
    "num_boxes = boxes.shape[0]\n",
    "print \"boxes.shape = \", boxes.shape\n",
    "print \"numb_boxes = \", num_boxes\n",
    "overlaps = np.zeros((num_boxes, num_classes), dtype = np.float32)\n",
    "print \"overlaps.shape = \", overlaps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_boxes.shape =  (5, 4)\n",
      "gt_classes.shape =  (5,)\n",
      "Help on built-in function bbox_overlaps:\n",
      "\n",
      "bbox_overlaps(...)\n",
      "    Parameters\n",
      "    ----------\n",
      "    boxes: (N, 4) ndarray of float\n",
      "    query_boxes: (K, 4) ndarray of float\n",
      "    Returns\n",
      "    -------\n",
      "    overlaps: (N, K) ndarray of overlap between boxes and query_boxes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gt_boxes = gt_roidb[0]['boxes']\n",
    "gt_classes = gt_roidb[0]['gt_classes']\n",
    "print 'gt_boxes.shape = ', gt_boxes.shape\n",
    "print 'gt_classes.shape = ', gt_classes.shape\n",
    "\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "from cython_bbox import bbox_overlaps\n",
    "help(bbox_overlaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_overlaps.shape =  (2443, 5)\n",
      "gt_overlaps[:5,:]:\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "gt_overlaps = bbox_overlaps(boxes.astype(np.float), gt_boxes.astype(np.float))\n",
    "print 'gt_overlaps.shape = ', gt_overlaps.shape\n",
    "print 'gt_overlaps[:5,:]:\\n', gt_overlaps[:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "** Now `gt_overlaps` is a `numpy.ndarray` with shape (2443, 5), one row for each ss-box, one colum for each ground-truth box. Each column is the IoUs between boxes and the ground-truth box**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(argmaxes) =  2443\n",
      "len(maxes) =  2443\n",
      "Help on built-in function argmax:\n",
      "\n",
      "argmax(...)\n",
      "    a.argmax(axis=None, out=None)\n",
      "    \n",
      "    Return indices of the maximum values along the given axis.\n",
      "    \n",
      "    Refer to `numpy.argmax` for full documentation.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    numpy.argmax : equivalent function\n",
      "\n",
      "Help on built-in function max:\n",
      "\n",
      "max(...)\n",
      "    a.max(axis=None, out=None)\n",
      "    \n",
      "    Return the maximum along a given axis.\n",
      "    \n",
      "    Refer to `numpy.amax` for full documentation.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    numpy.amax : equivalent function\n",
      "\n"
     ]
    }
   ],
   "source": [
    "argmaxes = gt_overlaps.argmax(axis = 1)\n",
    "maxes = gt_overlaps.max(axis = 1)\n",
    "print 'len(argmaxes) = ', len(argmaxes)\n",
    "print 'len(maxes) = ', len(maxes)\n",
    "help(gt_overlaps.argmax)\n",
    "help(gt_overlaps.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "I = np.where(maxes > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1111,)\n"
     ]
    }
   ],
   "source": [
    "I = I[0]\n",
    "print I.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "overlaps[I, gt_classes[argmaxes[I]]] = maxes[I]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Well, now  `overlaps` is a `numpy.ndarray` with shape (2443, 5),  recording the maximum IoUs of each ss-box with repect to the 21 classes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "overlaps = scipy.sparse.csr_matrix(overlaps)\n",
    "ss_roidb = []\n",
    "ss_roidb.append({'boxes' : boxes,\n",
    "              'gt_classes' : np.zeros((num_boxes,), dtype = np.int32),\n",
    "              'gt_overlaps' : overlaps,\n",
    "              'flipped': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 5. Back to `def selective_search_roidb(self)`\n",
    "\n",
    "Above is what the two line mainly about:\n",
    "```python\n",
    " gt_roidb = self.gt_roidb()\n",
    " ss_roidb = self._load_selective_search_roidb(gt_roidb)\n",
    "```\n",
    "\n",
    "The next line is: \n",
    "```python\n",
    "roidb = datasets.imdb.merge_roidbs(gt_roidb, ss_roidb)\n",
    "```\n",
    "This line is to merge the `gt_roidb` and `ss_roidb` by stacking one above the other to make the final `roidb`.\n",
    "```python\n",
    "a = gt_roidb\n",
    "b = ss_roidb\n",
    "## def merge_roidbs(a, b)\n",
    "    assert len(a) == len(b)\n",
    "    for i in xrange(len(a)):\n",
    "        a[i]['boxes'] = np.vstack((a[i]['boxes'], b[i]['boxes']))\n",
    "        a[i]['gt_classes'] = np.hstack((a[i]['gt_classes'],\n",
    "                                        b[i]['gt_classes']))\n",
    "        a[i]['gt_overlaps'] = scipy.sparse.vstack([a[i]['gt_overlaps'],\n",
    "                                                   b[i]['gt_overlaps']])\n",
    "    return a                                                   \n",
    "```\n",
    "Note that this code requires `len(gt_roidb) == len(ss_roidb)`, we cannot run this code. Because `ss_roidb` only contains the the data for one image (possibly the first image).\n",
    "\n",
    "Anyway, let's just run one iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a = gt_roidb[0]\n",
    "b = ss_roidb[0]\n",
    "a['boxes'] = np.vstack((a['boxes'], b['boxes']))\n",
    "a['gt_classes'] = np.hstack((a['gt_classes'], b['gt_classes']))\n",
    "a['gt_overlaps'] = scipy.sparse.vstack([a['gt_overlaps'], b['gt_overlaps']])\n",
    "\n",
    "roidb = []\n",
    "roidb.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Now let's we are ready to look into code under directory `./lib/roi_data_layer/`**\n",
    "---\n",
    "### 6. `def prepare_roidb(imdb)` in `roidb.py` (called in `train.py`)\n",
    "```python\n",
    " \"\"\"Enrich the imdb's roidb by adding some derived quantities that\n",
    "    are useful for training. This function precomputes the maximum\n",
    "    overlap, taken over ground-truth boxes, between each ROI and\n",
    "    each ground-truth box. The class with maximum overlap is also\n",
    "    recorded.\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb = \n",
      "{'boxes': array([[262, 210, 323, 338],\n",
      "       [164, 263, 252, 371],\n",
      "       [  4, 243,  66, 373],\n",
      "       ..., \n",
      "       [349, 363, 370, 374],\n",
      "       [349, 363, 371, 374],\n",
      "       [349, 363, 377, 374]], dtype=uint16), 'gt_overlaps': <2448x21 sparse matrix of type '<type 'numpy.float32'>'\n",
      "\twith 1116 stored elements in Compressed Sparse Row format>, 'gt_classes': array([9, 9, 9, ..., 0, 0, 0], dtype=int32), 'flipped': False}\n"
     ]
    }
   ],
   "source": [
    "imdb = roidb[0]\n",
    "print \"imdb = \\n\", imdb\n",
    "#print \"\\nimdb['gt_overlaps'][:5] = \", imdb['gt_overlaps'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "roidb[0]['image'] = 'imdb.image_path_at(i)' # path to the real `.jpg` image\n",
    "# need `gt_overlaps` as a dence array for argmax\n",
    "gt_overlaps = roidb[0]['gt_overlaps'].toarray()\n",
    "# max overlap with gt over classes (columns)\n",
    "max_overlaps = gt_overlaps.max(axis = 1)\n",
    "# gt class that had the max overlap\n",
    "max_classes = gt_overlaps.argmax(axis = 1)\n",
    "\n",
    "roidb[0]['max_classes'] = max_classes\n",
    "roidb[0]['max_overlaps'] = max_overlaps\n",
    "\n",
    "# sanity checks\n",
    "# max overlap of 0 => class should be zero (background)\n",
    "zero_inds = np.where(max_overlaps == 0)[0]\n",
    "assert all(max_classes[zero_inds] == 0)\n",
    "\n",
    "# max overlap > 0 => class should not be zero (must be a fg class)\n",
    "nonzero_inds = np.where(max_overlaps > 0)[0]\n",
    "assert all(max_classes[nonzero_inds] != 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 7. **def add_bbox_regression_targets(roidb)** in `roidb.py` (called in `train.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.          1.          1.          1.          1.          0.94051784]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Add information needed to train bounding-box regressors.\"\"\"\n",
    "assert len(roidb) > 0\n",
    "assert 'max_classes' in roidb[0], 'Did you call `prepare_roidb first?'\n",
    "\n",
    "num_images = len(roidb) ## 1 \n",
    "num_classes = roidb[0]['gt_overlaps'].shape[1]\n",
    "# for im_i in xrange(num_images):\n",
    "im_i = 0\n",
    "rois = roidb[im_i]['boxes']\n",
    "max_overlaps = roidb[im_i]['max_overlaps']\n",
    "max_classes = roidb[im_i]['max_classes']\n",
    "## next cell => roidb[im_i]['bbox_targets'] = _compute_targets(rois, max_overlaps, max_classes)\n",
    "print max_overlaps[np.where(max_overlaps > 0.9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.          0.          0.26967221  0.04045853]\n",
      " [ 0.          1.          0.          0.03106951  0.        ]\n",
      " [ 0.          0.          1.          0.          0.        ]\n",
      " [ 0.26967221  0.03106951  0.          1.          0.07799909]\n",
      " [ 0.04045853  0.          0.          0.07799909  1.        ]\n",
      " [ 0.07851504  0.          0.          0.07600596  0.54537122]\n",
      " [ 0.          0.          0.60328947  0.          0.        ]\n",
      " [ 0.01548975  0.          0.          0.08071749  0.56129032]\n",
      " [ 0.03827751  0.          0.          0.06703411  0.71949602]\n",
      " [ 0.00971997  0.          0.          0.05467996  0.57777778]\n",
      " [ 0.01295996  0.          0.          0.05731257  0.6       ]\n",
      " [ 0.05024577  0.          0.          0.06568403  0.63931624]\n",
      " [ 0.07531944  0.          0.          0.08171886  0.61538462]\n",
      " [ 0.01765121  0.          0.          0.0522897   0.51587302]\n",
      " [ 0.0355434   0.          0.          0.05325624  0.58490566]\n",
      " [ 0.03859098  0.          0.          0.05192878  0.52542373]\n",
      " [ 0.          0.          0.68815142  0.          0.        ]\n",
      " [ 0.          0.          0.50928982  0.          0.        ]\n",
      " [ 0.          0.          0.63257739  0.          0.        ]\n",
      " [ 0.          0.          0.64127448  0.          0.        ]\n",
      " [ 0.          0.          0.51516854  0.          0.        ]\n",
      " [ 0.          0.          0.67575534  0.          0.        ]\n",
      " [ 0.          0.          0.63682164  0.          0.        ]\n",
      " [ 0.          0.          0.50750215  0.          0.        ]\n",
      " [ 0.          0.          0.66208548  0.          0.        ]\n",
      " [ 0.          0.          0.69539939  0.          0.        ]\n",
      " [ 0.5540814   0.          0.          0.4266128   0.02607184]\n",
      " [ 0.57926692  0.          0.          0.41522697  0.02698145]\n",
      " [ 0.40073918  0.07800073  0.          0.5060241   0.01773836]\n",
      " [ 0.          0.          0.86153294  0.          0.        ]\n",
      " [ 0.          0.          0.83060175  0.          0.        ]\n",
      " [ 0.          0.          0.81541421  0.          0.        ]\n",
      " [ 0.          0.          0.87294365  0.          0.        ]\n",
      " [ 0.          0.          0.82664854  0.          0.        ]\n",
      " [ 0.          0.          0.88712871  0.          0.        ]\n",
      " [ 0.          0.          0.86455741  0.          0.        ]\n",
      " [ 0.          0.          0.94051784  0.          0.        ]\n",
      " [ 0.          0.          0.74015179  0.          0.        ]\n",
      " [ 0.          0.          0.53504974  0.          0.        ]\n",
      " [ 0.          0.          0.73777403  0.          0.        ]\n",
      " [ 0.12230792  0.65279682  0.          0.10179641  0.        ]\n",
      " [ 0.14457277  0.58821801  0.          0.11775077  0.        ]\n",
      " [ 0.21499531  0.51693659  0.          0.08542714  0.        ]\n",
      " [ 0.14706414  0.5537252   0.          0.12459191  0.        ]\n",
      " [ 0.12506402  0.62397091  0.          0.10429448  0.        ]\n",
      " [ 0.          0.          0.52092126  0.          0.        ]\n",
      " [ 0.07448141  0.67418977  0.          0.08071363  0.        ]\n",
      " [ 0.20592306  0.50513514  0.          0.07922931  0.        ]\n",
      " [ 0.          0.          0.54622153  0.          0.        ]\n",
      " [ 0.13438821  0.5345038   0.          0.06892231  0.        ]\n",
      " [ 0.          0.50607042  0.          0.00327899  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "rois = rois.astype(np.float, copy = False)\n",
    "# Inidces of ground-truth RoIs\n",
    "gt_inds = np.where(max_overlaps == 1)[0]\n",
    "# Indices of examples for which we try to make predictions\n",
    "BBOX_THRESH = 0.5\n",
    "ex_inds = np.where(max_overlaps > BBOX_THRESH)[0]\n",
    "\n",
    "# Get IoU overlap between each ex RoI and gt RoI\n",
    "import cython_bbox\n",
    "ex_gt_overlaps = cython_bbox.bbox_overlaps(rois[ex_inds, :], rois[gt_inds, :])\n",
    "print ex_gt_overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Find which gt ROI each ex ROI has max overlap with:\n",
    "## this will be the ex ROI's gt target\n",
    "\n",
    "EPS = 1e-14\n",
    "gt_assignment = ex_gt_overlaps.argmax(axis=1)\n",
    "gt_rois = rois[gt_inds[gt_assignment], :]\n",
    "ex_rois = rois[ex_inds, :]\n",
    "\n",
    "ex_widths = ex_rois[:, 2] - ex_rois[:, 0] + EPS\n",
    "ex_heights = ex_rois[:, 3] - ex_rois[:, 1] + EPS\n",
    "ex_ctr_x = ex_rois[:, 0] + 0.5 * ex_widths\n",
    "ex_ctr_y = ex_rois[:, 1] + 0.5 * ex_heights\n",
    "\n",
    "gt_widths = gt_rois[:, 2] - gt_rois[:, 0] + EPS\n",
    "gt_heights = gt_rois[:, 3] - gt_rois[:, 1] + EPS\n",
    "gt_ctr_x = gt_rois[:, 0] + 0.5 * gt_widths\n",
    "gt_ctr_y = gt_rois[:, 1] + 0.5 * gt_heights\n",
    "\n",
    "targets_dx = (gt_ctr_x - ex_ctr_x) / ex_widths\n",
    "targets_dy = (gt_ctr_y - ex_ctr_y) / ex_heights\n",
    "targets_dw = np.log(gt_widths / ex_widths)\n",
    "targets_dh = np.log(gt_heights / ex_heights)\n",
    "\n",
    "targets = np.zeros((rois.shape[0], 5), dtype=np.float32)\n",
    "targets[ex_inds, 0] = max_classes[ex_inds]\n",
    "targets[ex_inds, 1] = targets_dx\n",
    "targets[ex_inds, 2] = targets_dy\n",
    "targets[ex_inds, 3] = targets_dw\n",
    "targets[ex_inds, 4] = targets_dh\n",
    "\n",
    "roidb[im_i]['bbox_targets'] = targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 8. **Now, let's go to `def get_minibatch(roidb, num_classes)` in `minibatch.py`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_images = 2  # sample two images\n",
    "rois_per_image = 128 / num_images # sample 128/2 = 64 rois per image\n",
    "fg_rois_per_image = np.round(0.25 * 64) # sample 64 * .25 = 16 rois as fg\n",
    "num_classes = 21 # 21 classes (including background)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. def _sample_rois(roidb, fg_rois_per_image, rois_per_image, num_classes):\n",
    "```python\n",
    "\"\"\"Generate a random sample of RoIs comprising foreground and background\n",
    "    examples.\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2    3    4 1208 1229 1278 1280 1281 1282 1283 1299 1319 1320\n",
      " 1321 1379 1381 1396 1397 1398 1413 1447 1456 1477 1478 1555 1556 1567 1745\n",
      " 1747 1752 1756 1759 1760 1761 1762 1767 1779 1792 1844 1848 1849 1851 1852\n",
      " 1857 1880 1881 1929 1983 2072]\n"
     ]
    }
   ],
   "source": [
    "labels = roidb[0]['max_classes']\n",
    "overlaps = roidb[0]['max_overlaps']\n",
    "rois = roidb[0]['boxes']\n",
    "# cfg.Train.FG_THRESH = 0.5\n",
    "FG_THRESH = 0.5\n",
    "# Select foreground RoIs as those with >= FG_THRESH overlap\n",
    "fg_inds = np.where(overlaps >= FG_THRESH)[0]\n",
    "print fg_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1792 1556 1278 1396 1555 1851    4 1456 1282 1929 1848 1447 1849 1381 1779\n",
      " 1857]\n",
      "Help on built-in function choice:\n",
      "\n",
      "choice(...)\n",
      "    choice(a, size=None, replace=True, p=None)\n",
      "    \n",
      "    Generates a random sample from a given 1-D array\n",
      "    \n",
      "            .. versionadded:: 1.7.0\n",
      "    \n",
      "    Parameters\n",
      "    -----------\n",
      "    a : 1-D array-like or int\n",
      "        If an ndarray, a random sample is generated from its elements.\n",
      "        If an int, the random sample is generated as if a was np.arange(n)\n",
      "    size : int or tuple of ints, optional\n",
      "        Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "        ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "        single value is returned.\n",
      "    replace : boolean, optional\n",
      "        Whether the sample is with or without replacement\n",
      "    p : 1-D array-like, optional\n",
      "        The probabilities associated with each entry in a.\n",
      "        If not given the sample assumes a uniform distribution over all\n",
      "        entries in a.\n",
      "    \n",
      "    Returns\n",
      "    --------\n",
      "    samples : 1-D ndarray, shape (size,)\n",
      "        The generated random samples\n",
      "    \n",
      "    Raises\n",
      "    -------\n",
      "    ValueError\n",
      "        If a is an int and less than zero, if a or p are not 1-dimensional,\n",
      "        if a is an array-like of size 0, if p is not a vector of\n",
      "        probabilities, if a and p have different lengths, or if\n",
      "        replace=False and the sample size is greater than the population\n",
      "        size\n",
      "    \n",
      "    See Also\n",
      "    ---------\n",
      "    randint, shuffle, permutation\n",
      "    \n",
      "    Examples\n",
      "    ---------\n",
      "    Generate a uniform random sample from np.arange(5) of size 3:\n",
      "    \n",
      "    >>> np.random.choice(5, 3)\n",
      "    array([0, 3, 4])\n",
      "    >>> #This is equivalent to np.random.randint(0,5,3)\n",
      "    \n",
      "    Generate a non-uniform random sample from np.arange(5) of size 3:\n",
      "    \n",
      "    >>> np.random.choice(5, 3, p=[0.1, 0, 0.3, 0.6, 0])\n",
      "    array([3, 3, 0])\n",
      "    \n",
      "    Generate a uniform random sample from np.arange(5) of size 3 without\n",
      "    replacement:\n",
      "    \n",
      "    >>> np.random.choice(5, 3, replace=False)\n",
      "    array([3,1,0])\n",
      "    >>> #This is equivalent to np.random.permutation(np.arange(5))[:3]\n",
      "    \n",
      "    Generate a non-uniform random sample from np.arange(5) of size\n",
      "    3 without replacement:\n",
      "    \n",
      "    >>> np.random.choice(5, 3, replace=False, p=[0.1, 0, 0.3, 0.6, 0])\n",
      "    array([2, 3, 0])\n",
      "    \n",
      "    Any of the above can be repeated with an arbitrary array-like\n",
      "    instead of just integers. For instance:\n",
      "    \n",
      "    >>> aa_milne_arr = ['pooh', 'rabbit', 'piglet', 'Christopher']\n",
      "    >>> np.random.choice(aa_milne_arr, 5, p=[0.5, 0.1, 0.1, 0.3])\n",
      "    array(['pooh', 'pooh', 'pooh', 'Christopher', 'piglet'],\n",
      "          dtype='|S11')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Guard against the case when an image has fewer than `fg_rois_per_image` foreground RoIs\n",
    "fg_rois_per_this_image = int(np.minimum(fg_rois_per_image, fg_inds.size))\n",
    "\n",
    "# Select foreground regions without replacement\n",
    "import numpy.random as npr\n",
    "if fg_inds.size > 0:\n",
    "    fg_inds = npr.choice(fg_inds, size = fg_rois_per_this_image, replace=False)\n",
    "print fg_inds\n",
    "help(npr.choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Select background RoIs as those within [BG_THRESH_LO, BG_THRESH_HI]\n",
    "BG_THRESH_LO = 0.1\n",
    "BG_THRESH_HI = 0.5\n",
    "bg_inds = np.where((overlaps < BG_THRESH_HI) &\n",
    "                   (overlaps > BG_THRESH_LO))[0]\n",
    "# Compute number of background RoIs to take from this image\n",
    "# (guarding against there being fewer than desired)\n",
    "bg_rois_per_this_image = rois_per_image - fg_rois_per_this_image\n",
    "bg_rois_per_this_image = np.minimum(bg_rois_per_this_image, bg_inds.size)\n",
    "# Sample background regions without replacement\n",
    "if bg_inds.size > 0:\n",
    "    bg_inds = npr.choice(bg_inds, size = bg_rois_per_this_image, replace = False)\n",
    "    \n",
    "# The indices that we're selecting (both fg and bg)\n",
    "keep_inds = np.append(fg_inds, bg_inds)\n",
    "\n",
    "labels = labels[keep_inds]\n",
    "# Clamp labels for the backgound RoIs to 0\n",
    "labels[fg_rois_per_this_image:] = 0\n",
    "\n",
    "print labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "overlaps = overlaps[keep_inds]\n",
    "rois = rois[keep_inds]\n",
    "## What left behind is how to get `bbox_targets` and `bbox_loss_weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bbox_target_data = roidb[0]['bbox_targets'][keep_inds, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 10. def _get_bbox_regression_labels(bbox_target_data, num_classes)\n",
    "``` python\n",
    "\"\"\"Bounding-box regression targets are stored in a compact form in the\n",
    "roidb.\n",
    "\n",
    "This function expands those targets into the 4-of-4*K representation used\n",
    "by the network (i.e. only one class has non-zero targets). The loss weights\n",
    "are similarly expanded.\n",
    "\n",
    "Returns:\n",
    "    bbox_target_data (ndarray): N x 4K blob of regression targets\n",
    "    bbox_loss_weights (ndarray): N x 4K blob of loss weights\n",
    "\"\"\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "print num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clss = bbox_target_data[:, 0]\n",
    "bbox_targets = np.zeros((clss.size, 4 * num_classes), dtype=np.float32)\n",
    "bbox_loss_weights = np.zeros(bbox_targets.shape, dtype=np.float32)\n",
    "inds = np.where(clss > 0)[0]\n",
    "for ind in inds:\n",
    "    cls = clss[ind]\n",
    "    start = 4 * cls\n",
    "    end = start + 4\n",
    "    ## the following three lines are added by jcsu\n",
    "    ## to convert `ind`, `start` and `end` from type `np.float64` to `np.int`\n",
    "    ind = int(ind)\n",
    "    start = int(start)\n",
    "    end = int(end)\n",
    "    bbox_targets[ind, start:end] = bbox_target_data[ind, 1:]\n",
    "    bbox_loss_weights[ind, start:end] = [1., 1., 1., 1.]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color = red> All five requred network input blobs: ` labels, overlaps, rois, bbox_targets, bbox_loss_weights` are finally obtained!!</font>**\n",
    "\n",
    "Arriving at this point, the data input layer `RoIDataLayer` becomes trivial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[to do]A Summary\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
