---
2016/11/22, Monday, Rainy & Blustery
---

    By Jincheng Su @ Hikvision, mail: jcsu14@fudan.edu.cn


Test the accuracy of the fine-tuned B-CNN model
---

### Data Set.

The `CUB-200-2011` is a dataset of birds of 200 categories containing 5794 images for testing and 5994 images for training. 
    Note that only 2/3 of the training set is used for training and 1/3 is left out for validation while fine-tuning. Therefore, training set and validataion set should be combined together and have an additional step of training.

### Have another step of training

The whole dataset is separated into three subset while `cub_get_database.m`. To use all the 5994 images for training, modify the setence in `run_experiments_bcnn_train.m` by setting the validation set be used as training set:

```[matlab]
% /path/to/bcnn/run_experiments_bcnn_train.m

    ...
    'numEpochs', 200, ... % resuming from epoch 100 to train for another 100 epochs
    ...
    % `1` for training, `2` for validation, `3` for testing.
    % Change the set labels `2` to `1` to combine training and validataion sets.
    imdb.images.set(imdb.images.set==2) = 1;
    ...
```

### Write code for testing the symmetric `B-CNN` model

The source code by default casts away the `linear classifier` layer and `softmaxloss` layer used for fine-tuning and train a set of `one-vs-all` linear SVMs on the extracted `bcnn` features extracted by the fine-tuned model.

However, training linear SVMs is infeasiblek due to the limit of memory of the available workstation. The source code did not provide code for testing a `BCNN` model with a softmax classifier.

We need to write code for testing.

```[matlab]
% /path/to/bcnn/test_bcnn_sym.m


% -------------------------------------------------------------------
% Test the accuracy of symmetric bcnn
% By Jincheng Su, mail: jcsu14@fudan.edu.cn
% Date: 2016/11/22
% -------------------------------------------------------------------

gpus = 1;
batchSize = 64;
% load models
%netmm = load('data/checkgpu_mm/cub-seed-01/fine-tuned-model/final-model.mat');
%netdd = load('data/checkgpu_vdvd/cub-seed-01/fine-tuned-model/final-model.mat');
netmm = load('data/checkgpu_mm/cub-seed-01/net-epoch-160.mat');
netdd = load('data/checkgpu_vdvd/cub-seed-01/net-epoch-109.mat');
%nett = netdd.net;
nett = netmm.net;

nett.layers{end}.type = 'softmax';
nett.layers{end}.name = 'predict';

% load datasets
imdbcub = load('data/checkgpu_vdvd/cub-seed-01/imdb/imdb-seed-1.mat');
cubDir = 'data/cub/images/';
num_total_images = numel(imdbcub.images.id);

% get all the image used for test
testImgs = find(imdbcub.images.set==3);
% get the corresponding labels

% -----------------------------------------------------------------------
% get 'averageImage', 'rgbMean', and 'rgbCovariance'
% -----------------------------------------------------------------------
bopts.numThreads = 6 ;
bopts.averageImage = [];
bopts = nett.meta.normalization ;
imageStatsPath = fullfile('data/checkgpu_mm/cub-seed-01/', 'imageStats.mat') ;
if exist(imageStatsPath)
  load(imageStatsPath, 'averageImage', 'rgbMean', 'rgbCovariance') ;
else
  [averageImage, rgbMean, rgbCovariance] = getImageStats(imdb, bopts) ;
  save(imageStatsPath, 'averageImage', 'rgbMean', 'rgbCovariance') ;
end

% -----------------------------------------------------------------------
% set train.bopts
% -----------------------------------------------------------------------
nett.meta.normalization.averageImage = rgbMean ;

[v,d] = eig(rgbCovariance) ;


test_bopts = nett.meta.normalization;
test_bopts.numThreads = 6 ;
test_bopts.averageImage = rgbMean;
test_bopts.transformation = 'f2' ; % 'f2'
test_bopts.rgbVariance = []; % 
test_bopts.scale = 2 ;

getBatch = getBatchSimpleNNWrapper(test_bopts) ;

% -----------------------------------------------------------------------
% begin testing the model
% -----------------------------------------------------------------------

% move CNN to GPU as needed
numGpus = numel(gpus) ;
if numGpus >= 1
  net_cpu = vl_simplenn_move(nett, 'gpu') ;
end

count = 0;
i = 0;
for batch = 1:batchSize:numel(testImgs)
    i = i+ 1;
    bs = min(batchSize, numel(testImgs) - batch + 1);
    batchStart = batch;
    batchEnd = min(batchStart +batchSize - 1, numel(testImgs));
    batchInds = testImgs(batchStart:batchEnd);
    %labels = imdbcub.images.label(batchInds);
    % get a batch of images as well as their labels
    [im, labels] = getBatch(imdbcub, batchInds);
    if numGpus >= 1
        im = gpuArray(im{1});
    end
    
    dzdy = [];
    res = [];
    res = vl_bilinearnn(net_cpu, im, dzdy, res, ...
        'accumulate', 0, ...
        'mode', 'normal', ...
        'conserveMemory', 1, ...
        'backPropDepth', 1, ...
        'sync', 1, ...
        'cudnn', 1);

    
    [val, ind] = max(res(end).x(1,1,:,:));
    
    numofbatch = batchEnd - batchStart + 1;    
    ind = reshape(ind, [1, numofbatch]);
    correctCnt = sum(labels == ind);

    fprintf('batch %3d/%3d, accuracy: %3d/%3d (%.4f) \n', i, ceil(numel(testImgs)/batchSize), ...
        correctCnt, numofbatch, correctCnt/numofbatch);
    
    count = count + correctCnt;
end

fprintf('Average accuracy on test set: %d/%d (%f) \n', count, numel(testImgs), count/numel(testImgs));
```

### Accuracy

The first 100 epochs are trained with 1/3 of training set being left out as validation. Epochs after that are trained combining the 2/3 training set and 1/3 validation set.

* **B-CNN[M, M]**

    Reported top1 accuracy: 78.1 %

    Reproduced top1 accuracy on test set:

        Epoch 130: 76.46%
        Epoch 140: 76.58%
        Epoch 150: 76.96%
        Epoch 160: 77.18%
        Epoch 170: 77.25%
        Epoch 180: 77.29%
        Epoch 181: 77.56%
        Epoch 182: 77.55%
        Epoch 183: 77.29%
        Epoch 185: 77.08%
        Epoch 188: 77.11%

	Speed:

 		37.5 frames/sec, 2.7 min/epoch

* **B-CNN[D, D]**

    Reported top1 accuracy: 84.0 %

    Reproduced top1 accuracy on test set:

        Epoch 110: 83.4 %
        Epoch 112: 83.57%
        Epoch 113: 83.64%
        Epoch 114: 83.76% (0.837591)
        Epoch 115: 83.60%
        Epoch 116: 83.90% (0.838971)

	Speed:

 		6.7 frames/sec, 15 min/epoch

* **B-CNN[D, M]**

    Reported top1 accuracy: 84.1 %

    Reproduced top1 accuracy on test set:

    The first 86 epochs use only 2/3 of the training set, leaving out 1/3 for validation

        Epoch 50: 80.17 %
        Epoch 70: 80.16 %
        Epoch 80: 80.27 %
        Epoch 86: 80.24 %
    
    Epochs beginning from 87 use the whole training set.

        Epoch 100: 83.10%
        Epoch 103: 83.09%
        Epoch 105: 83.34%
        Epoch 107: 83.26%
        Epoch 109: 83.29% 
        Epoch 110: 83.83% 
        Epoch 111: 83.00%
        Epoch 112: 83.20% --
        Epoch 113: 83.62%
        Epoch 115: 83.59% -- 82.92%
        Epoch 120: 83.34% -- 82.76%


	Speed:

 		6.7 frames/sec, 15 min/epoch
