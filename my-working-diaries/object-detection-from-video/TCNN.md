T-CNN:Tubelets with Convolutional Neural Networks for Object Detection from Videos
---
## 引言
ILSVRC2015 引入了一项新的竞赛：视频目标检测，将目标检测应用到了视频领域。在该竞赛中，目标检测系统需要自动框定每段视频的每一帧中的所有目标，并指定类别。这些目标来自30个类别。然而测试集中并没有提供任何标注信息。

在一段视频的各帧之间，目标的外观和大小经常会随着时间发生剧烈的变化，目标常常被遮挡，还有移动模糊，静态图像数据和视频数据之间的不匹配等。因此相比于静态图像的目标检测，视频目标检测更加具有挑战性。

相比于单张静态图像中只有空间这一维度，视频中增加了时间这一维度，并产生了更加复杂的语境和更丰富的语意。因此静态图像中的目标检测方法比如**R-CNN**、**Fast R-CNN**、**Faster R-cnn**等，无法直接应用于视频目标检测。

* 时间信息
    一个有效的视频目标检测系统应当首先保证目标的外观和位置在时间上具有一致性和连续性，即目标检测结果的位置和类别置信度不能剧烈变化。

    为了保证目标检测结果在时间上的一致性，一个很自然的想法就是将目标检测结果传播到相邻帧中，然后应用极大值抑制。因为如果某帧中存在目标，那么相邻帧中很有可能也存在这一目标。该想法只能保证目标在少数帧（即短时间）中的一致性。

    为了保证目标检测结果在时间上的长期一致性，需要对检测结果施加长期约束（**long-term constraints**）。对此，比较自然的想法是对每个检测到的目标进行追踪，或者通过**spatio-temporal object proposal**算法，得到该目标在各个帧中的检测框，并形成一个检测框序列，称为小管（**tubelet**)。一个小管就是一个长期约束。直观上来说，如果一个小管中的大多数检测框都具有比较高的置信度，那么小管上其他置信度较低的检测框的置信度应当要被提高。

* 语境信息
    虽然VID数据集中的各个视频段包含了数量不等的目标类别，从统计上来看，每个视频段通常只包含很少数量的类别，并且这些类别之间具有一定的相关性。（也就是说视频段中的目标类别在时空上具有聚类性质。）


## T-CNN 概览

T-CNN 的思路是

1. 利用现有的静态图像目标检测方法，比如**DeepID-Net**和**CRAFT**，对各个视频段中的各个帧进行目标检测。得到的检测结果称为**静态检测结果**。

2. 对**静态检测结果**进行**MCS**和**MGP**处理

3. 对**静态检测结果**进行**Tubelet re-scoring**处理

4. 把步骤2和3中处理的结果进行综合

## 静态图像目标检测

利用现有的静态图像目标检测方法对单帧进行目标检测。文中利用了**DeepID-Net**和**CRAFT**两个模型。对于这两个模型中的每一个模型，在提取了**Object region proposal**之后，都训练多个不同的分类网络对这些**proposal**进行评分，然后利用贪婪搜索进行分数平均。


由于这两个模型都是对**R-CNN**进行一些繁琐复杂的修补，实现起来十分繁琐。本次实现将直接采用**Faster R-CNN**。

#### DeepID-Net

**DeepID-Net**是R-CNN的扩展。

1. 该模型利用**Selective Search (SS)**和**Edge Boxes (EB)**两个算法提取**object region proposal**。
2. 用一个在 **ImageNet** 上预训练好的 **AlexNet** 标注每一个**proposal box**属于各个类别的分数（概率），共有200个类别。
3. 根据各个**proposal box**在200个类别中的最大分数（概率），设定一个阈值<font color=red>（**超参数1**）</font>，最大分数小于该阈值的**box**将被当作负样本而移除掉。该过程大概会移除94%的**proposal box**，同时仍能保证90%左右的召回率（**recall rate**)。
4. whatever ...

#### CRAFT

**CRAFT**是**Faster R-CNN**的一个扩展。

## MCS & MGP

**MCS & MGP**直接对**Faster R-CNN**的目标检测结果进行处理。

#### MCS -- Multi-context suppression

对于每一帧，都有数百个**region proposal**，**Faster R-CNN**可以计算出每个**proposal**属于30个类别中各个类别的检测分数。对于每一段视频，将所有帧的所有**proposal box**的所有分数降序排列。检测分数高于给定阈值<font color=red> (**超参数2**) </font>的类别被认为是高置信度类别，其他类别则被认为是低置信度类别。地置信度类别的分数将被减去某个给定值<font color=red>（**超参数3**）</font>进行抑制。

该阈值和被减去的值通过在验证集上进行贪婪搜索得到。

#### MGP -- Motion-guided propagation

**MCS**可以降低错正率，但是无法恢复错负的检测结果。产生错负检测的原因可能是没有一个**region proposal**对目标覆盖足够的区域，也可能是目标的姿势变化、运动模糊等不利于目标检测。由于前后帧高度相关，相邻帧中目标的位置和检测分数也应当是高度相关的，通过将相邻帧的检测结果加入到当前帧中，可以恢复一部分错负的检测结果。

对于每一个 **region proposal**，计算其**Box**中的平均光流向量，然后将该**Box**的坐标根据该平均光流向量传播到相邻帧中，其检测分数保持不变。

## Tubelet re-scoring

#### High confidence tracking
对一段视频中的每一个目标类别，对高置信度的**proposal**在时间上进行双向追踪。追踪的起点**box**被称为锚点（**anchor**)，它是置信度最高的检测结果。

1. 从置信度最高的锚点开始进行双向追踪，当追踪的置信度低于某个阈值<font color=red> （**超参数3**）</font>（论文中采用0.1概率值）时，提前停止追踪（**early stop**)。得到一个**box**序列，即一个小管（**tubelet**）。

1. 将所有与该小管中的**box**重叠率（IoU）大于某一个阈值<font color=red> （**超参数4**） </font> (论文中采用0.3）的**proposal**排除，从剩余的**proposal box**中选择置信度最高的作为新的锚点。

1. 重复步骤1和2，直到剩下的所有**proposal**的置信度低于某一个阈值<font color=red> （**超参数5**） </font> 。对30个**VID**中的每一个类别都进行同样的目标追踪。


#### Spatial max-pooling

在进行高置信度追踪之后，对于每一个类别，都可以得到一些小管。接下来对小管中的**box**进行空间极大值池化：

1. 对于小管上的每一个**box**，从静态图像目标检测中的**proposal box**中选取所有与小管上该**box**的覆盖率**IoU**大于某一个阈值<font color=red> （**超参数6**） </font>（论文中采用了0.5）的**box**。 

1. 从上一个步骤中得到的所有**box**，包括小管上的该**box**，选取检测分数最大的，替换小管上的该**box**。

如果小管上的**box**实际上确实是正的，然而检测分数比较低，该池化操作可以提高它的检测分数。

#### Tubelet classificaion

接下来要对空间极大值池化后的小管进行正负二分类，然而将正负小管分别映射到不同的范围中。

1. 以小管中的最高的k个分数（**top-k**)作为分类特征，训练一个贝叶斯分类器对小管进行正负二分类。

1. 分类后，正样本的分数 **min-max** 映射到 [0.5, 1]区间，负样本则映射到[0, 0.5]区间。

## Experiments

#### 数据集

1. 训练集包含3862段全标注（**fully-annotated**）的视频片段，每个视频从6帧到5492帧不等。

1. 验证集包含555段全标注的视频片段，每个视频从11帧到2898帧不等。

1. 测试集包含937个视频片段，标注没有公开。

因此文中的各种性能都是在验证集上计算的。

#### 参数设置

* 数据配置

	VID数据集的训练集总帧数超过112万，从数字上看，这么大的数据量用来训练30个类别的分类器似乎已经足够。然而，同一个视频片段背景单一，相邻多帧的图像差异较小。因此训练集存在着大量的数据冗余，数据多样性很差。所以可以对训练集进行数据扩充。在比赛任务中，可以从**ILSVRC DET**和**ILSVRC LOC**数据集中抽取包含**VID**类别的图像进行扩充。

	对于静态图像目标检测，论文中利用了**DET**数据集的所有图像，对**VID**训练集进行采样，使得**DET**图片数：**VID**图片数 = 2：1，然后将这些图像混合在一起，对静态图像目标检测模型中的卷积网络进行细调。


* 超参数设置
	MGP向前和向后分别传播3帧。
	MCS中，对一个视频片段所有帧的所有**proposal box**的所有分数按降序排列，选出前0.0003的**box**，其中的类别将被认为是高置信度类别，低置信度类别的分数将会被减去0.4。

* 网络配置
	在**DeepID-Net**和**CRAFT**模型中，才用了具有**BN**层的**GoogLeNet**和**VGG**模型。



Object Detection from Video Tubelets with Convolutional Neural Networks
---
